In [1]:
import numpy as np
import pandas as pd
import re
1. Как создать pd.Series из листа, numpy array и словаря(dict)? (★☆☆)

In [2]:
mylist = list('abcedfghijklmnopqrstuvwxyz')
myarr = np.arange(26)
mydict = dict(zip(mylist, myarr))

pd.Series(mylist)
pd.Series(myarr)
pd.Series(mydict)
Out[2]:
a     0
b     1
c     2
e     3
d     4
f     5
g     6
h     7
i     8
j     9
k    10
l    11
m    12
n    13
o    14
p    15
q    16
r    17
s    18
t    19
u    20
v    21
w    22
x    23
y    24
z    25
dtype: int64
2. Как сделать превратить индексы из датафрейма в колонку? (★☆☆)

In [3]:
df=pd.DataFrame(['a', 'b', 'c'])

df['index'] = df.index
3. Как из нескольких pd.Series сделать один датафрейм? (★★☆)

(hint: pd.concat или словарь с колонками)

In [4]:
df1=pd.Series(['a', 'b', 'c'])
df2=pd.Series(['aa', 'b1', 'c2'])
df3=pd.Series(['44', '55', '66'])

pd.concat([df1, df2, df3], axis=1)
Out[4]:
0	1	2
0	a	aa	44
1	b	b1	55
2	c	c2	66
4. Как получить строки из series A, которые не содержатся в series B? (★★☆)

In [5]:
df1=pd.Series(['a', 'b', 'c'])
df2=pd.Series(['a', 'b1', 'c2'])

df1[~df1.apply({*df2}.__contains__)]
Out[5]:
1    b
2    c
dtype: object
5. Как получить из series/dataframe минимум, 25й персентиль, медиану, 75тый персентиль, максимум? (★☆☆)

(hint: использовать одну команду)

In [6]:
df1=pd.Series(np.arange(10, 99))

df1.describe()
Out[6]:
count    89.000000
mean     54.000000
std      25.836021
min      10.000000
25%      32.000000
50%      54.000000
75%      76.000000
max      98.000000
dtype: float64
6. Как получить частоту\долю для всех уникальных объектов в series? (★☆☆)

In [7]:
df1=pd.Series(['a', 'b', 'c', 'g', 'v', 'a', 'a', 'a', 'u', 'a', 'b', 'c', 'c'])

df1.value_counts()
Out[7]:
a    5
c    3
b    2
g    1
v    1
u    1
dtype: int64
7. Как оставить только топ-2 самых часто встречающихся значений, а все остальные значения заменить на 'other'? (★★☆)

In [8]:
df1=pd.Series(['a', 'b', 'c', 'g', 'v', 'a', 'a', 'a', 'u', 'a', 'b', 'c', 'c'])

df1.where(df1.apply({*df1.value_counts().index[:2]}.__contains__), 'other')
Out[8]:
0         a
1     other
2         c
3     other
4     other
5         a
6         a
7         a
8     other
9         a
10    other
11        c
12        c
dtype: object
8. Как разбить колонку с числовыми значениями на 10 групп одинакового размера? (★★☆)

(hint: pd.qcut)

In [9]:
s = pd.Series(np.random.random(20))

pd.qcut(s, 10)
Out[9]:
0      (0.809, 0.903]
1      (0.352, 0.408]
2      (0.437, 0.647]
3     (0.0253, 0.175]
4      (0.809, 0.903]
5      (0.265, 0.306]
6      (0.222, 0.265]
7      (0.408, 0.437]
8      (0.647, 0.809]
9     (0.0253, 0.175]
10     (0.352, 0.408]
11     (0.408, 0.437]
12     (0.265, 0.306]
13     (0.175, 0.222]
14     (0.175, 0.222]
15     (0.222, 0.265]
16     (0.306, 0.352]
17     (0.647, 0.809]
18     (0.437, 0.647]
19     (0.306, 0.352]
dtype: category
Categories (10, interval[float64]): [(0.0253, 0.175] < (0.175, 0.222] < (0.222, 0.265] < (0.265, 0.306] ... (0.408, 0.437] < (0.437, 0.647] < (0.647, 0.809] < (0.809, 0.903]]
9. Как найти позиции чисел, которые делятся на 3 без остатка из series? (★★☆)

(можно с помощью numpy и с помощью pandas)

In [10]:
s = pd.Series(np.random.randint(0, 4, 10))

s[s%3==0].index
Out[10]:
Int64Index([3, 4, 5, 8], dtype='int64')
10. Как извлечь из series строки по индексам? (★☆☆)

In [11]:
s = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))
pos = [0, 4, 8, 14, 20]

s[pos]
Out[11]:
0     a
4     e
8     i
14    o
20    u
dtype: object
11. Как сделать stack двух series вертикально и горизонтально? (★☆☆)

(hint: pd.append, pd.concat)

In [12]:
s1 = pd.Series(range(5))
s2 = pd.Series(list('abcde'))

pd.concat([s1, s2], axis=1)
pd.concat([s1, s2], axis=0)
Out[12]:
0    0
1    1
2    2
3    3
4    4
0    a
1    b
2    c
3    d
4    e
dtype: object
12. Как получить позиции строк из series A из другого series B? (★☆☆)

(можно с помощью numpy и с помощью pandas)

In [13]:
s1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])
s2 = pd.Series([1, 3, 10, 13])

s1.loc[s1.isin(s2)].index
Out[13]:
Int64Index([0, 4, 5, 8], dtype='int64')
13. Как вычислить среднеквадратическую ошибку для истинных и предсказанных значений? (★★☆)

In [14]:
truth = pd.Series(range(10))
pred = pd.Series(range(10)) + np.random.random(10)

np.sqrt(((pred - truth) ** 2).mean())
Out[14]:
0.6575561510301133
14. Как конвертировать каждый первый элемент строке в series в верхний регистр? (★★☆)

In [15]:
s = pd.Series(['how', 'to', 'kick', 'ass?'])

s.str.title()
Out[15]:
0     How
1      To
2    Kick
3    Ass?
dtype: object
15. Как посчитать количество символов в каждой строке? (★★☆)

In [16]:
s = pd.Series(['how', 'to', 'kick', 'ass?'])

s.str.len()
Out[16]:
0    3
1    2
2    4
3    4
dtype: int64
16. Как преобразовать даты в виде строк в timeseries? (★☆☆)

(hint: pd.to_datetime)

In [17]:
s = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])

pd.to_datetime(s)
Out[17]:
0   2010-01-01 00:00:00
1   2011-02-02 00:00:00
2   2012-03-03 00:00:00
3   2013-04-04 00:00:00
4   2014-05-05 00:00:00
5   2015-06-06 12:20:00
dtype: datetime64[ns]
17. Как получить день месяца, номер недели, день года и день недели из даты в виде строки? (★★☆)

In [18]:
s = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])
s = pd.to_datetime(s)

print("Date: ", s.dt.strftime('%d'))

print("Week number: ", s.dt.strftime('%U'))

print("Day number of year: ", s.dt.strftime('%j'))

print("Day of week: ", s.dt.strftime('%w'))
Date:  0    01
1    02
2    03
3    04
4    05
5    06
dtype: object
Week number:  0    00
1    05
2    09
3    13
4    18
5    22
dtype: object
Day number of year:  0    001
1    033
2    063
3    094
4    125
5    157
dtype: object
Day of week:  0    5
1    3
2    6
3    4
4    1
5    6
dtype: object
18. Как конвертировать дату из формата месяц-год в формат год-месяц-первое число? (★★☆)

(hint: .strftime('%Y-%m-%d'))

In [19]:
s = pd.Series(['Jan 2017', 'Feb 2019', 'Mar 2012'])

pd.to_datetime(s).dt.strftime('%Y-%m-%d')
Out[19]:
0    2017-01-01
1    2019-02-01
2    2012-03-01
dtype: object
19. Как отфильтровать слова, содержащие не менее 2 гласных? (★★☆)

In [20]:
s = pd.Series(['Kitty', 'Cat', 'Plan', 'Python', 'Money'])

s[s.str.count('(?i)[aeiou]') >= 2]
Out[20]:
4    Money
dtype: object
20. Заполните все пропущенные даты от минимальной до максимальной, значения при этом дожны быть равны предыдущей не пропущеной дате (★★★)

In [21]:
s = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))

min_date = s.index.min()
max_date = s.index.max()
date_range = pd.date_range(min_date, max_date)
s_ = pd.Series([np.nan] * len(date_range), index=date_range)
s_[s.index] = s
s_.fillna(method='ffill')
Out[21]:
2000-01-01     1.0
2000-01-02     1.0
2000-01-03    10.0
2000-01-04    10.0
2000-01-05    10.0
2000-01-06     3.0
2000-01-07     3.0
2000-01-08     3.0
Freq: D, dtype: float64
21. Считайте файл из CSV-файла по строчно и добавьте считанные строки в датафрейм (файл data/BostonHousing.csv)? (★★☆)

(hint: csv reader)

In [22]:
import csv

arr = []

with open ('data/accel.csv','r') as csv_file:
    reader = csv.reader(csv_file)
    for row in reader:
        arr.append(row)

pd.DataFrame(np.array(arr[1::]), columns=arr[0])
Out[22]:
interval	axis	reading
0	0	X	0
1	0	Y	0.5
2	0	Z	1
3	1	X	0.1
4	1	Y	0.4
5	1	Z	0.9
6	2	X	0.2
7	2	Y	0.3
8	2	Z	0.8
9	3	X	0.3
10	3	Y	0.2
11	3	Z	0.7
22. Как изменить значения столбца при импорте csv в фрейм данных? Импортируйте датасет с помощью pd.read_csv, но колонку 'medv' (median house value) измените так, что если value < 25 = ‘Low’ и если > 25 = ‘High’. (★★☆)

(hint: pd.read_csv(....., converts={}))

In [23]:
data = pd.read_csv("data/accel.csv", converters={'medv': 'insert_data'})
23. Как импортировать только указанные столбцы('crim' и 'medv') и только n строк из CSV-файла? (★☆☆)

In [24]:
data = pd.read_csv("data/accel.csv", usecols=['interval', 'axis'], nrows=3)
24. Как получить кол-во строк, кол-во столбцов, тип столбцов, кол-во столбцов с таким типом данных, итоговую статистику каждого столбца датафрейма? (★☆☆)

In [25]:
df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')

df.shape

df.dtypes

df.dtypes.value_counts()

df.describe()
Out[25]:
Min.Price	Price	Max.Price	MPG.city	MPG.highway	EngineSize	Horsepower	RPM	Rev.per.mile	Fuel.tank.capacity	Passengers	Length	Wheelbase	Width	Turn.circle	Rear.seat.room	Luggage.room	Weight
count	86.000000	91.000000	88.000000	84.000000	91.000000	91.000000	86.000000	90.000000	87.000000	85.000000	91.000000	89.000000	92.000000	87.000000	88.000000	89.000000	74.000000	86.000000
mean	17.118605	19.616484	21.459091	22.404762	29.065934	2.658242	144.000000	5276.666667	2355.000000	16.683529	5.076923	182.865169	103.956522	69.448276	38.954545	27.853933	13.986486	3104.593023
std	8.828290	9.724280	10.696563	5.841520	5.370293	1.045845	53.455204	605.554811	486.916616	3.375748	1.045953	14.792651	6.856317	3.778023	3.304157	3.018129	3.120824	600.129993
min	6.700000	7.400000	7.900000	15.000000	20.000000	1.000000	55.000000	3800.000000	1320.000000	9.200000	2.000000	141.000000	90.000000	60.000000	32.000000	19.000000	6.000000	1695.000000
25%	10.825000	12.350000	14.575000	18.000000	26.000000	1.800000	100.750000	4800.000000	2017.500000	14.500000	4.000000	174.000000	98.000000	67.000000	36.000000	26.000000	12.000000	2647.500000
50%	14.600000	17.700000	19.150000	21.000000	28.000000	2.300000	140.000000	5200.000000	2360.000000	16.500000	5.000000	181.000000	103.000000	69.000000	39.000000	27.500000	14.000000	3085.000000
75%	20.250000	23.500000	24.825000	25.000000	31.000000	3.250000	170.000000	5787.500000	2565.000000	19.000000	6.000000	192.000000	110.000000	72.000000	42.000000	30.000000	16.000000	3567.500000
max	45.400000	61.900000	80.000000	46.000000	50.000000	5.700000	300.000000	6500.000000	3755.000000	27.000000	8.000000	219.000000	119.000000	78.000000	45.000000	36.000000	22.000000	4105.000000
25. Как извлечь номер строки и столбца конкретной ячейки с заданным критерием? (★☆☆)

In [26]:
df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')

df[df.Price == df.Price.max()]
Out[26]:
Manufacturer	Model	Type	Min.Price	Price	Max.Price	MPG.city	MPG.highway	AirBags	DriveTrain	...	Passengers	Length	Wheelbase	Width	Turn.circle	Rear.seat.room	Luggage.room	Weight	Origin	Make
58	Mercedes-Benz	300E	Midsize	43.8	61.9	80.0	19.0	25.0	Driver & Passenger	Rear	...	5.0	NaN	110.0	69.0	37.0	NaN	15.0	3525.0	non-USA	Mercedes-Benz 300E
1 rows × 27 columns

26. Переименнуйте колонку Type в CarType, в столбцах с '.' в названии замените её на '_'. Как добавить ко всем названиям колонок суффиксы? (★☆☆)

In [27]:
df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')

df.columns = df.columns.str.replace(".", "_")

df.rename(columns={'Type':'CarType'}, inplace=True)

#Добавляется с помощью add_suffix
27. Проверьте есть ли в датафрейме пропуски? Если да, посчитайте кол-во nan\none в каждом столбце датафрейма (★★☆)

In [28]:
df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')

df.isnull().sum(axis = 0)
Out[28]:
Manufacturer           4
Model                  1
Type                   3
Min.Price              7
Price                  2
Max.Price              5
MPG.city               9
MPG.highway            2
AirBags                6
DriveTrain             7
Cylinders              5
EngineSize             2
Horsepower             7
RPM                    3
Rev.per.mile           6
Man.trans.avail        5
Fuel.tank.capacity     8
Passengers             2
Length                 4
Wheelbase              1
Width                  6
Turn.circle            5
Rear.seat.room         4
Luggage.room          19
Weight                 7
Origin                 5
Make                   3
dtype: int64
28. Как заменить отсутствующие значения нескольких числовых столбцов средним? (★★☆)

In [29]:
df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')

df.fillna(df.mean(), inplace=True)
29. Как выбрать конкретный столбец из датафрейма в качестве датафрейма, а не series? (★☆☆)

In [30]:
df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')

type(df[['Price']])
Out[30]:
pandas.core.frame.DataFrame
30. Как изменить порядок столбцов данных? (☆☆☆)

In [31]:
df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')

#df = df[['columns list here']]
31. Как установить количество строк и столбцов, отображаемых в выводе? (☆☆☆)

(hint: pd.set_option)

In [32]:
df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')

pd.set_option('display.max_rows', 5)
pd.set_option('display.max_columns', 5)
32. Как получить номер строки, в которой содержится максимальное значение в столбце? (★★☆)

In [33]:
df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))

df[df['b'] == df['b'].max()].index
Out[33]:
Int64Index([0], dtype='int64')
33. Как получить последние n строк датафрейма с суммой строк 100? (★★★)

In [34]:
df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))

df[df.sum(axis=1) == 100].tail(5)
Out[34]:
a	b	c
Выбросы (оutliers)
5 Ways to Detect Outliers/Anomalies That Every Data Scientist Should Know (Python Code)
https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623

34. Как найти и заменить выбросы из столбца Series или датафрейма? (★★★)

Замените все значения из столбца ниже 5того и больше 95го персентиля, на пограничные значения.

(hint: .quantile())

In [35]:
s = pd.Series(np.logspace(-2, 2, 30))

s = s.clip(lower=s.quantile(0.05), upper=s.quantile(0.95))
35. Попробуйте реализовать метод Interquartile Range (IQR) (★★★)

Почитать про него можно по ссылке выше.

In [36]:
s = pd.Series(np.logspace(-2, 2, 30))

np.percentile(s, 75, interpolation='higher') - np.percentile(s, 25, interpolation='lower')
Out[36]:
10.734000253021803
36. Как поменять местами две строки данных? (★★★)

In [37]:
df = pd.DataFrame(np.arange(25).reshape(5, -1))

df.iloc[1:3] = np.flip(df.to_numpy()[1:3], axis=0)
df
Out[37]:
0	1	2	3	4
0	0	1	2	3	4
1	10	11	12	13	14
2	5	6	7	8	9
3	15	16	17	18	19
4	20	21	22	23	24
one-hot-encoding
37. Как создать однозначные кодировки категориальной переменной? (★★★)

Сделайте one-hot кодировку столбца 'a'.

In [38]:
df = pd.DataFrame([['aa', 'kek'], ['ba', 'lol'], ['ab', 'kek'], ['aa', 'lol'], ['cc', 'kek']], columns=['a', 'b'])

pd.get_dummies(df['a'])
Out[38]:
aa	ab	ba	cc
0	1	0	0	0
1	0	0	1	0
2	0	1	0	0
3	1	0	0	0
4	0	0	0	1
38. Нормализуйте все столбцы в датафрейме. (★★★)

a) Нормализовать все столбцы df путем вычитания среднего значения столбца и деления на стандартное отклонение.

b) Трансформируйте все столбцы df так, чтобы минимальное значение в каждом столбце было 0, а max = 1.

In [39]:
df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))

for col in list(df.columns):
    df[col] = (df[col]-df[col].mean())/df[col].std()
    
for col in list(df.columns):
    df[col][df[col] == df[col].min()] = 0
    df[col][df[col] == df[col].max()] = 1
39. Как получить конкретную группу из датафрейма сгруппированного по ключу? (★★★)

Сгруппируйте по 'name', и выведите данные по группе 'orange'.

(hint: groupby(), get_group())

In [40]:
df = pd.DataFrame({'name': ['apple', 'banana', 'orange'] * 3,
                   'taste': np.random.rand(9),
                   'price': np.random.randint(0, 15, 9)})

df.groupby('name').get_group('orange')
Out[40]:
name	taste	price
2	orange	0.271056	13
5	orange	0.266463	3
8	orange	0.097833	10
40. Как вычислить среднее значение по столбцу 'price' по каждому фрукту в датафрейме и сохранить сгруппированный столбец как другой столбец (не индекс)? (★★★)

In [41]:
df = pd.DataFrame({'name': ['apple', 'banana', 'orange'] * 3,
                   'taste': np.random.rand(9),
                   'price': np.random.randint(0, 15, 9)})

mean_by_names = df.groupby('name')['price'].mean()
df.join(mean_by_names, on='name', rsuffix='_mean')
Out[41]:
name	taste	price	price_mean
0	apple	0.127000	7	2.666667
1	banana	0.566856	11	11.666667
...	...	...	...	...
7	banana	0.220652	14	11.666667
8	orange	0.248702	12	11.333333
9 rows × 4 columns

41. Как объединить два датафрейма по двум столбцам, чтобы в них остались только общие строки? (★★★)

Сделать merge двух датафреймов по колонкам ['fruit', 'weight'] и ['pazham', 'kilo'].

(hint: pd.merge https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html#merge )

In [42]:
df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,
                    'weight': ['high', 'medium', 'low'] * 3,
                    'price': np.random.randint(0, 15, 9)})

df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,
                    'kilo': ['high', 'low'] * 3,
                    'price': np.random.randint(0, 15, 6)})

df1.merge(df2, left_on = ['fruit', 'weight'], right_on = ['pazham', 'kilo'], how = 'inner')
Out[42]:
fruit	weight	...	kilo	price_y
0	apple	high	...	high	0
1	apple	high	...	high	0
...	...	...	...	...	...
4	orange	low	...	low	3
5	orange	low	...	low	3
6 rows × 6 columns

42. Как удалить строки из датафрейма А, которые присутствуют в датафрейме B? (★★★)

In [43]:
df1 = pd.DataFrame({'fruit': ['apple', 'orange', 'banana'] * 3,
                    'weight': ['high', 'medium', 'low'] * 3,
                    'price': np.arange(9)})

df2 = pd.DataFrame({'fruit': ['apple', 'orange', 'pine'] * 2,
                    'weight': ['high', 'medium'] * 3,
                    'price': np.arange(6)})

#pd.merge(df1, df2, how='cross')
43. Как получить номера строк, в которых совпадают значения двух столбцов? (★★★)

(hint: np.where)

In [44]:
df = pd.DataFrame({'fruit1': np.random.choice(['apple', 'orange', 'banana'], 10),
                    'fruit2': np.random.choice(['apple', 'orange', 'banana'], 10)})


df[df.apply(pd.Series.nunique, axis=1) == 1]
Out[44]:
fruit1	fruit2
0	banana	banana
1	orange	orange
7	orange	orange
8	banana	banana
44. Создайте столбец a_shift со сдвигом на одну строку назад. (★★★)

(hint: .shift())

In [45]:
df = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))

df['a_shift'] = df['a'].shift(axis=0)
45. Как разбить текстовый столбец на три отдельных столбца? (★★★)

Разбить на три столбцы STD, City, State

In [46]:
df = pd.DataFrame(["STD, City    State",
"33, Kolkata    West Bengal",
"44, Chennai    Tamil Nadu",
"40, Hyderabad    Telengana",
"80, Bangalore    Karnataka"], columns=['row'])

df.row.str.split(r", |    ", expand=True)
Out[46]:
0	1	2
0	STD	City	State
1	33	Kolkata	West Bengal
2	44	Chennai	Tamil Nadu
3	40	Hyderabad	Telengana
4	80	Bangalore	Karnataka
46. Ну а теперь все вместе. (★★★★★★★★★★)
Заменяем все точки в названии на '_'
Выделить категориальные признаки
Посчитать кол-во уникальных значений во всех текстовых\категориальных столбцах.
Колонки с только уникальными значениями удаляем (например Model и Make)
Для столбцов у которых значений более 10, оставляем топ 10 значений, остальные заменяем на 'other'
Числовые столбцы проверяем на пропуски. Подсчитываем кол-во nan\none и делим на размер датафрейма -сохраняем в отдельный датафрейм, это доля пропусков в каждом столбце
Чистим выбросы. Во всех числовых столбцах заменяем все значения столбца меньше 5го персентиля и больше 95ого персентиля на эти пограничные значения.
Заполняем пропуски в числовых столбцах на среднее по столбцу, в текстовых столбцах на 'other'
Все категориальные признаки превращаем в one-hot-encoding
Создать новый столбец Length_Width = Length * Width
Столбцы MPG_cityми MPG_highway из MPG перевести в единицы LPG (литры \100 км) = (100 3,785) / (MPG 1,609)
Посчитать среднюю цену по каждому типу машины у каждого производителя
Посчитать максимальные Length и Width по Type
Посчитать кол-во моделей машин по типу машины и наличию подушки безопасности (агрегирование по столбцам Type и AirBags)
Посчитать кол-во машин по каждому типу машины у каждого производителя(агрегирование по столбцам Type и Manufacturer)
Посчитать кол-во машин по Manufacturer-Man_trans_avail
Вывести у какой модели, какого изготовителя максимальная вместимость по пассажирам
In [47]:
df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')
df.columns = df.columns.str.replace('.', '_', regex=False)
categorical = df.select_dtypes(exclude='number').columns
cat_cols = df.select_dtypes(exclude='number').columns
df[cat_cols].nunique()
not_unique_cols = df.columns[~(df.nunique() == df.count())]
df = df[not_unique_cols]
In [48]:
cat_cols = df.select_dtypes(exclude='number').columns

gt_10_unique = df[df[cat_cols].columns[df[cat_cols].nunique() > 10]]

for col in gt_10_unique:
    top_10_values = df[col].value_counts().nlargest(10).index
    df[col][~df[col].isin(top_10_values)] = 'other'
In [49]:
num_cols = df.select_dtypes(include='number').columns
nan_part_df = pd.DataFrame(df[num_cols].isna().sum() / len(df), columns=['nan_part'])
In [50]:
num_cols = df.select_dtypes(include='number').columns
for col in num_cols:
    col_series = df[col]
    q05 = col_series.quantile(q=0.05)
    q95 = col_series.quantile(q=0.95)
    col_series.iloc[col_series < q05] = q05
    col_series.iloc[col_series > q95] = q95
    df.loc[:, col] = col_series
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
d:\work\lib\site-packages\pandas\core\indexing.py:670: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  iloc._setitem_with_indexer(indexer, value)
In [51]:
num_cols = df.select_dtypes(include='number').columns
df[num_cols] = df[num_cols].fillna(df[num_cols].mean())

cat_cols = df.select_dtypes(exclude='number').columns
df[cat_cols] = df[cat_cols].fillna('other')
In [52]:
for col in cat_cols:
    one_hot = pd.get_dummies(df[col])
    df = df.join(one_hot, rsuffix='_one_hot')
df.drop(columns=cat_cols, inplace=True)
In [53]:
df['Length_Width'] = df['Length'] * df['Width']
In [54]:
df['MPG_city'] = (100 * 3.785) / (df['MPG_city'] * 1.609)
df.rename(columns={'MPG_city': 'LPG_city'}, inplace=True)

df['MPG_highway'] = (100 * 3.785) / (df['MPG_highway'] * 1.609)
df.rename(columns={'MPG_highway': 'LPG_highway'}, inplace=True)
In [55]:
df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')
df.groupby(['Manufacturer', 'Type']).mean()['Price']
df.groupby('Type').max()[['Length', 'Width']]
df.groupby(['Type', 'AirBags']).count()['Model']
df.groupby(['Manufacturer', 'Type']).count()['Model']
df.groupby(['Manufacturer', 'Man.trans.avail']).count()['Model']
df.groupby(['Manufacturer', 'Model']).max()['Passengers']
Out[55]:
Manufacturer  Model  
Acura         Integra    5.0
Audi          100        6.0
                        ... 
Volkswagen    Passat     5.0
Volvo         240        5.0
Name: Passengers, Length: 88, dtype: float64
47. Перевести индексы первого и третьего уровня в колонки

In [56]:
df = pd.DataFrame({
    'school_code': ['s001','s002','s003','s001','s002','s004'],
    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],
    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],
    'date_of_birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],
    'weight': [35, 32, 33, 30, 31, 32],
    't_id': ['t1', 't2', 't3', 't4', 't5', 't6']})
df1 = df.set_index(['t_id', 'school_code', 'class'])

df1.reset_index(level=0, inplace=True)
df1.reset_index(level=1, inplace=True)
48. Вывести строку из Series и DataFrame по заданному индексу

In [57]:
ds = pd.Series([1,3,5,7,9,11,13,15], index=[0,1,2,3,4,5,7,8])
df = pd.DataFrame({
    'school_code': ['s001','s002','s003','s001','s002','s004'],
    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],
    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],
    'date_of_birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],
    'weight': [35, 32, 33, 30, 31, 32]})

indx = 4

ds.iloc[indx]
df.iloc[indx]
Out[57]:
school_code              s002
class                       V
name             Gino Mcneill
date_of_birth      11/05/2002
weight                     31
Name: 4, dtype: object
49. Найти индексы строк с пропущенными данными

In [58]:
df = pd.DataFrame({
    'school_code': ['s001','s002','s003','s001','s002','s004'],
    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],
    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],
    'date_of_birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],
    'weight': [35, None, 33, 30, 31, None]},
     index = ['t1', 't2', 't3', 't4', 't5', 't6'])

df[df.isnull().any(axis=1)].index
Out[58]:
Index(['t2', 't6'], dtype='object')
50. Сделать left join датафреймов

In [59]:
data1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],
                     'key2': ['K0', 'K1', 'K0', 'K1'],
                     'P': ['P0', 'P1', 'P2', 'P3'],
                     'Q': ['Q0', 'Q1', 'Q2', 'Q3']}) 
data2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],
                      'key2': ['K0', 'K0', 'K0', 'K0'],
                      'R': ['R0', 'R1', 'R2', 'R3'],
                      'S': ['S0', 'S1', 'S2', 'S3']})

data = pd.merge(data1, data2, how='left')
51. Соединить два датафрейма

In [60]:
data1 = pd.DataFrame({'A': ['A0', 'A1', 'A2'],
                      'B': ['B0', 'B1', 'B2']},
                     index=['K0', 'K1', 'K2'])

data2 = pd.DataFrame({'C': ['C0', 'C2', 'C3'],
                      'D': ['D0', 'D2', 'D3']},
                     index=['K0', 'K2', 'K3'])

data1.merge(data2,left_index=True, right_index=True)
Out[60]:
A	B	C	D
K0	A0	B0	C0	D0
K2	A2	B2	C2	D2
52. Сгруппировать датафрейм по полям 'customer_id' и 'salesman_id' и отсортировать по sum of purch_amt внутри каждой группы

In [61]:
df = pd.DataFrame({
'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],
'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],
'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],
'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],
'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})

df.groupby(['customer_id', 'salesman_id']).sum().sort_values('purch_amt', ascending = 'True')
Out[61]:
ord_no	purch_amt
customer_id	salesman_id		
3005	5007	70011	75.29
3001	5003	70004	110.50
...	...	...	...
3005	5003	70003	2480.40
5001	210023	8870.86
9 rows × 2 columns

53. Сгруппировать датафрейм по месяцу и году из даты ord_date и найти общее количество заказов по годам и по месяцам

In [62]:
df = pd.DataFrame({
'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],
'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],
'ord_date': ['05-10-2012','09-10-2012','05-10-2013','08-17-2013','10-09-2013','07-27-2014','10-09-2012','10-10-2012','10-10-2012','06-17-2014','07-08-2012','04-25-2012'],
'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],
'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})

df['month'] = pd.to_datetime(df['ord_date']).dt.strftime('%m')
df['year'] = pd.to_datetime(df['ord_date']).dt.strftime('%Y')
df.groupby(['month','year']).count()
Out[62]:
ord_no	purch_amt	ord_date	customer_id	salesman_id
month	year					
04	2012	1	1	1	1	1
05	2012	1	1	1	1	1
...	...	...	...	...	...	...
10	2012	3	3	3	3	3
2013	1	1	1	1	1
10 rows × 5 columns

Regular expressions with Pandas
1. Выделить в отдельную колонку event_id первую цифру в кавычках, во вторую колонку event_probability вероятность (★☆☆)

In [63]:
df=pd.DataFrame({'col1':["{'34': 0.9839372122311848}",
                         "{'77': 0.6724645988404411}",
                         "{'77': 0.6491011266207006}",
                         "{'77': 0.6123085784265466}",
                         "{'34': 0.87}",
                         "{'77': 0.6225699652019304}",
                         "{'3': 0.5470808226524633}",
                         "{'77': 0.6233849004135044}",
                         "{'77': 0.7050888998743866}",
                         "{'52': 0.8945052223205372}"]})

df['evend_id'] = df['col1'].str.findall(r"'\d+'").astype(str).str.replace("""[\[\]"']""", '', regex=True)
df['event_probability'] = df['col1'].str.findall(r"0\.[0-9]*").astype(str).str.replace(r"(\[')|('\])", '', regex=True)
df
Out[63]:
col1	evend_id	event_probability
0	{'34': 0.9839372122311848}	34	0.9839372122311848
1	{'77': 0.6724645988404411}	77	0.6724645988404411
...	...	...	...
8	{'77': 0.7050888998743866}	77	0.7050888998743866
9	{'52': 0.8945052223205372}	52	0.8945052223205372
10 rows × 3 columns

2. Удалите все тэги, переносы строк из текстов новостей (★★★)

(hint: df.column.str())

In [64]:
#df = pd.read_excel('news.xlsx') У меня нет экслея, поэтому закоментил, но все верно

#df['text'] = df['text'].str.replace('\n','')
3. Проставьте флаг в колонку source_ria если текст новости содержит: риа новости, тасс, коммерсант. Перед поиском переведите тексты в lower и удалите все кроме букв. Данные после чистки из предыдушего задания (★★★)

(hint: df.column.str())

In [65]:
#df['source_ria'] = df['text'].str.lower().str.replace(r'[^a-zA-Zа-яА-ЯёЁ]', '').apply(lambda x: re.findall('риа новости',x)+re.findall('тасс',x)+re.findall('коммерсант',x))
4. Отфильтруйте строки с валидными емейлами (★★★)

In [66]:
emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com', 'kek lol@mail.ru'])

emails[emails.apply(lambda x: bool(re.fullmatch(r'\w{1,}@[a-z]{1,}\.(com|co|ru)',x)))]
Out[66]:
1    rameses@egypt.com
2            matt@t.co
3    narendra@modi.com
dtype: object
5. Напишите паттерн для поиска строки содержащей только буквы в верхнем и нижнем регистре, цифры и подчеркивание

In [67]:
''.join(re.findall(r'[а-яА-Яa-zA-Z\d_]', 'qwer1234'))
''.join(re.findall(r'[а-яА-Яa-zA-Z\d_]', '##%#$#$word001+_*&h^e&y*'))
Out[67]:
'word001_hey'
6. Замените пробелы на подчеркивание и наоборот

In [68]:
'qwe yu'.replace(' ','_').replace('_',' ')
Out[68]:
'qwe yu'
7. Найдите слова длиной 3,4,5

In [69]:
re.findall(r'\s*([a-zA-Zа-яА-ЯёЁ]{3,5})\s{1,}','LOLOL reee neow aa')
Out[69]:
['LOLOL', 'reee', 'neow']
8. Сделайте регистронезависимую замену(replace) во входной строке

In [70]:
'LOLOL reee neow aa'.lower().replace(r'reee','aa')
Out[70]:
'lolol aa neow aa'
